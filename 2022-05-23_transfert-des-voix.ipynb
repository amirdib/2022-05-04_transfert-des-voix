{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tl;dr : *Inférence du transfert des voix entre candidats.*\n",
    "\n",
    "Afin d'analyser les résultats des élections, par exemple les dernières élections présidentielles de 2022 en France, et de mieux comprendre la dynamique des choix de vote entre les différents groupes de population, il peut être utile d'utiliser des outils d'apprentissage automatique pour inférer des données *a priori* cachées dans les données. En particulier, inspiré par cet [article du Monde](https://www.lemonde.fr/les-decodeurs/article/2022/05/04/election-presidentielle-2022-quels-reports-de-voix-entre-les-deux-tours_6124672_4355770.html), on peut se poser la question de savoir si on peut extraire depuis les données brutes des élections une estimation des report de voix entre les choix de vote au premier tour et ceux qui sont effectués au deuxième tour.\n",
    "\n",
    "Pour cela nous allons utiliser les outils mathématiques de l'apprentissage automatique et en particulier l'utilisation des probabilités. Cette théorie va nous permettre d'exprimer le fait que les résultats telles qu'ils sont obtenus peuvent présenter une variabilité mais que celle-ci réelle résulte de préférence de chaque individu dans la population votante. En particulier, on peut considérer que chaque individu va avoir une préférence pour chacun des candidats au premier et second tour et que les votes effectués vont correspondre à la réalisation de ces préférences (en effet, on ne peut voter que pour un candidat par scrutin). \n",
    "\n",
    "Bien sûr on a accès ni au vote de chaque individu et encore moins à ses préférences. Mais comme mais comme chaque bureau de vote présente des variabilité liée au contexte local et qui fait que la population a une préférence pour certains choix plutôt que d'autres, on peut considérer chaque bureau de vote comme une population individuelle pour lequel nous allons essayer de prédire les résultats du vote au deuxième tour. Cette prediction, si elle est efficace, peut donner une idée du transfert de vote entre les deux tours qui a lieu en fonction des préférences des votes de chaque individu.\n",
    "\n",
    "<!-- TEASER_END -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Celà se modélise mathématiquement par un [processus de Bernoulli](https://fr.wikipedia.org/wiki/Processus_de_Bernoulli) relatif à ces préférences.\n",
    "\n",
    "Grâce à l'ouverture des données (notamment pour la recherche), on peut obtenir librement les résultats des [premier](https://www.data.gouv.fr/fr/datasets/election-presidentielle-des-10-et-24-avril-2022-resultats-definitifs-du-1er-tour/) et [second](https://www.data.gouv.fr/fr/datasets/election-presidentielle-des-10-et-24-avril-2022-resultats-definitifs-du-2nd-tour/) tours. Il est intéressant de noter que ses résultats sont indiqués pour chacun des bureaux de vote. \n",
    "\n",
    "Pour cela nous allons faire deux hypothèses: \n",
    "\n",
    "Tout d'abord nous allons estimer que pour chaque individu, il existe une préférence pour les candidats du premier tour ainsi que pour les candidats du deuxieme tour. Si on note les différentes alternatives au premier tour comme $i \\in \\{ \\text{'nul'}, \\text{'abstention'}, \\ldots, \\text{'Macron'}, \\text{'Poutou'} \\}$ et au deuxième tour  $j \\in \\{ \\text{'nul'}, \\text{'abstention'}, \\ldots, \\text{'Macron'}, \\text{'Le Pen'} \\}$. Alors, on peut écrire pour chaque individu $k$ les probabilités de vote $p^k_i$ et $q^k_j$ (chacune de ces valeurs étant comprises entre $0$ et $1$ représentant un biais de probabilité pour chacune des alternatives). On pourra vérifier que $\\forall k$ (pour tout individu),  $\\sum_i p^k_i = 1$ et $\\sum_j q^k_j = 1$.\n",
    "\n",
    "Avec une telle modélisation on peut prévoir les résultats du vote car les préférences de chacun individu pour telle ou telle choix doit se révéler au niveau de la population totale suivant le théorème central limite qui indique que la moyenne observée tend vers ces probabilités avec une précision (inverse de la variance) qui augmente linéairement avec le nombre d'observations. En particulier les résultats des votes au premier et second tour seront donnés par respectivement $\\frac 1 K \\cdot \\sum_k p^k_i$ et $\\frac 1 K \\cdot \\sum_k q^k_j$ avec $K$ la taille de la population (nous vérifierons ce point plus bas)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une deuxième hypothèse que nous allons faire et que si on considère la transition entre les préférences qui sont faites au premier tour et celles qui sont faites au second tour, les préférences évoluent avec chaque invidu mais la transition est homogène au sein de la population (par exemple \"une personne qui choisit de s'abstenir s'abstiendra\"). C'est certe une hypothèse grossière mais assez générale pour refléter les tendances au niveau de la population globale. Cette hypothèse est basée sur la modélisation de séquence d'événements aléatoires basé sur un [processus dit de Markov](https://fr.wikipedia.org/wiki/Cha%C3%AEne_de_Markov). En particulier nous allons formaliser cette hypothèse en faisant l'hypothèse de l'existence d'une matrice de transition $M$ qui permet de prédire la préférence $\\hat{q}^k_j$ d'un individu au second tour à partir de ses préférences au premier tour. En particulier, cette hypothèse peut être formulée comme un simple produit matriciel :\n",
    "\n",
    "$$\n",
    "\\hat{q}^k_j = \\sum_i M_{i, j} \\cdot p^k_i \n",
    "$$\n",
    "\n",
    "En termes plus simples, cette formule exprime que la préférence d'un individu au second tour et le mélange de ses préférences individuelles au premier tour avec des poids indiquant les affinités entre les différentes alternatives aux deux tours. Il est important de noter qu'il existe une contrainte  pour chaque colonne de cette matrice de transition de sorte que la somme des différentes éléments sur les différentes lignes de la matrice pour chaque colonne est égal à $1$ : $\\forall j$, $ \\sum_i M_{i, j} = 1$. Cette propriété découle des contraintes de représentation des préférences au premier et au deuxième tour que nous avons évoquées plus haut ($\\sum_i p^k_i = 1$ et $\\sum_j q^k_j = 1$).\n",
    "\n",
    "D'une cette certaine façon, cette matrice de transition décrit exactement les affinités de chacun des individus pour les différents choix de vote au niveau de la population globale. C'est donc un indicateur des report de vote qui vont être effectivement effectués entre les deux tours."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Collecte des données\n",
    "\n",
    "La première partie de ce travail consiste à collecter les données et elle est représenté d'une façon utile. On va utiliser les données disponibles sur https://www.data.gouv.fr en se concentrant sur les résultats définitifs par bureau de vote. \n",
    "Commençons notre procédure avec le traitement des données du premier tour. Une fois que nous aurons décortiqué cette méthode, nous passerons au deuxième tour.\n",
    "\n",
    "### Données du premier tour\n",
    "\n",
    "Pour cela nous allons utiliser deux premières librairie python : `numpy` pour le traitement de données numériques puis `pandas` pour la représentation deces données sous forme de tableau tableaux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut directement enregistrer à partir de l'adresse des données puis extraire ses données numériques depuis le tableau Excel grâce a la [fonction suivante](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_excel.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "BadZipFile",
     "evalue": "File is not a zip file",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadZipFile\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01murllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrequest\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39murlretrieve(url, fname)\n\u001b[0;32m----> 9\u001b[0m T1 \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/io/excel/_base.py:457\u001b[0m, in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, decimal, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[1;32m    456\u001b[0m     should_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 457\u001b[0m     io \u001b[38;5;241m=\u001b[39m \u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m io\u001b[38;5;241m.\u001b[39mengine:\n\u001b[1;32m    459\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    460\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    461\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    462\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/io/excel/_base.py:1376\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[1;32m   1374\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxls\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1375\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1376\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[43minspect_excel_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1377\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\n\u001b[1;32m   1378\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1379\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1380\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1381\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExcel file format cannot be determined, you must specify \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1382\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man engine manually.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1383\u001b[0m         )\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/io/excel/_base.py:1268\u001b[0m, in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1265\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m peek\u001b[38;5;241m.\u001b[39mstartswith(ZIP_SIGNATURE):\n\u001b[1;32m   1266\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1268\u001b[0m zf \u001b[38;5;241m=\u001b[39m \u001b[43mzipfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mZipFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1270\u001b[0m \u001b[38;5;66;03m# Workaround for some third party files that use forward slashes and\u001b[39;00m\n\u001b[1;32m   1271\u001b[0m \u001b[38;5;66;03m# lower case names.\u001b[39;00m\n\u001b[1;32m   1272\u001b[0m component_names \u001b[38;5;241m=\u001b[39m [name\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m zf\u001b[38;5;241m.\u001b[39mnamelist()]\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.9/3.9.12_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/zipfile.py:1266\u001b[0m, in \u001b[0;36mZipFile.__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps)\u001b[0m\n\u001b[1;32m   1264\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1265\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m-> 1266\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_RealGetContents\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1267\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m   1268\u001b[0m         \u001b[38;5;66;03m# set the modified flag so central directory gets written\u001b[39;00m\n\u001b[1;32m   1269\u001b[0m         \u001b[38;5;66;03m# even if no files are added to the archive\u001b[39;00m\n\u001b[1;32m   1270\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_didModify \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.9/3.9.12_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/zipfile.py:1333\u001b[0m, in \u001b[0;36mZipFile._RealGetContents\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1331\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m BadZipFile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile is not a zip file\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1332\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m endrec:\n\u001b[0;32m-> 1333\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m BadZipFile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile is not a zip file\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1334\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdebug \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1335\u001b[0m     \u001b[38;5;28mprint\u001b[39m(endrec)\n",
      "\u001b[0;31mBadZipFile\u001b[0m: File is not a zip file"
     ]
    }
   ],
   "source": [
    "fname = '/tmp/T1.xlsx'\n",
    "\n",
    "if not os.path.isfile(fname):\n",
    "    url = 'https://static.data.gouv.fr/resources/election-presidentielle-des-10-et-24-avril-2022-resultats-definitifs-du-1er-tour/20220414-152612/resultats-par-niveau-burvot-t1-france-entiere.xlsx' # XLSX\n",
    "    import urllib.request\n",
    "    urllib.request.urlretrieve(url, fname)\n",
    "\n",
    "\n",
    "T1 = pd.read_excel(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut avoir une première idée de ces données et du nombre total de bureaux de vote :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T1.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les données sont organisées suivant des colonnes qui vont représenter les différents choix et aussi d'autres métadonnées. Il va falloir faire quelques hypothèses pour récupérer les données utiles…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T1.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Première colonne concerne les nuls, blancs et abstention, que l'on peut enregistrer dans un nouveau tableau :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = T1[['Nuls', 'Blancs', 'Abstentions']].copy()\n",
    "df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### extraction des résultats de vote"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les 23 premières colonnes correspondent aux métadonnées :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T1.columns[:23]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les colonnes suivant la colonne numéro 23 vont concerner les résultats candidats par candidats :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_start = 23\n",
    "col_par_cdt = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut extraire les noms des candidats présents au premier tour :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidats = T1.iloc[0][col_start::col_par_cdt]\n",
    "candidats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut par exemple extraire les résultats pour le premier bureau de vote et donner le nombre de suffrages exprimés pour chaque candidat :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "résultats = T1.iloc[0][(col_start+2)::col_par_cdt]\n",
    "résultats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grâce à ces connaissances, nous allons pouvoir maintenant récolter les données pour chaque candidat et pour tous les bureaux de vote en utilisant la fonction suivante :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_candidat, candidat in enumerate(candidats):\n",
    "    i_col = col_start + i_candidat*col_par_cdt + 2\n",
    "    print('# colonne', i_col, ' résultats=', T1.iloc[:, i_col].values)\n",
    "    df_1[candidat] = T1.iloc[:, i_col].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons récolté les données utiles dans un nouveau tableau :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_1.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ceci nous permet par exemple d'extraire les résultats pour un candidat donné et pour tous les bureaux de vote :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1['POUTOU']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En particulier, on a le nombre suivant de bureaux de vote :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et on peut calculer pour chaque alternative le nombre total de choix ainsi que le nombre total de choix dans les data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.sum(), df_1.sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Par exemple, on note qu'environ 13 millions de personnes se sont abstenues, alors que environ 10 millions de personnes ont voté pour Macron."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sous un format graphique on peut représenter ainsi les résultats du vote au premier tour et pour cela nous allons utiliser la librairie `matplotlib`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(13, 5))\n",
    "k = df_1.sum()/df_1.sum().sum()\n",
    "ax = k.plot.bar(ax=ax)\n",
    "ax.set_xlabel('Choix 1er tour')\n",
    "ax.set_ylabel('Pourcentage');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque le fort taux d'abstention qui a été observé au premier tour, ainsi que les deux candidats qui se distinguent par le plus grand nombre de voix et qui sont sélectionnés pour le second tour."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### données du 2ème tour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons maintenant répéter la même opération pour les données obtenues au deuxième tour :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = '/tmp/T2.xlsx'\n",
    "\n",
    "if not os.path.isfile(fname):\n",
    "    url = 'https://static.data.gouv.fr/resources/election-presidentielle-des-10-et-24-avril-2022-resultats-definitifs-du-2nd-tour/20220428-142301/resultats-par-niveau-burvot-t2-france-entiere.xlsx' # XLSX\n",
    "    import urllib.request\n",
    "    urllib.request.urlretrieve(url, fname)\n",
    "\n",
    "T2 = pd.read_excel(fname)\n",
    "\n",
    "T2.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On vérifie que les données sont une nouvelle fois organisé suivant la même structure :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T2.columns[:23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T2.columns[23:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T2.iloc[0, 23:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_start = 23\n",
    "col_par_cdt = 7\n",
    "candidats = T2.iloc[0][col_start::col_par_cdt]\n",
    "candidats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une fois cette vérification faite nous pouvons extraire les données dans un nouveau tableau :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_2 = T2[['Nuls', 'Blancs', 'Abstentions']].copy()\n",
    "#df_1 = df_1.rename(columns={\"Nuls\": \"1_Nuls\", \"Abstentions\": \"1_Abstentions\"})\n",
    "df_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous vérifions aussi que nous avons le même nombre de bureaux de vote :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_candidat, candidat in enumerate(candidats):\n",
    "    i_col = col_start + i_candidat*col_par_cdt + 2\n",
    "    print(i_col, T2.iloc[:, i_col].values)\n",
    "    df_2[candidat] = T2.iloc[:, i_col].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De la même façon que pour le premier tour, nous pouvons représenter les résultats totaux obtenus au second tour de façon graphique :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(13, 5))\n",
    "k = df_2.sum()/df_2.sum().sum()\n",
    "ax = k.plot.bar(ax=ax)\n",
    "ax.set_xlabel('Candidat')\n",
    "#ax.set_xlim(1, 10)\n",
    "#ax.set_xticks(np.arange(1, 10)+.5)\n",
    "#ax.set_xticklabels(np.arange(1, 10)) , rotation=45\n",
    "ax.set_ylabel('pourcentage');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### non aux nans\n",
    "\n",
    "Certains bureaux de vote n'ont pas de votants au premier ou au deuxieme. Ceci peut engendrer des problèmes numériques en générant des divisions par zéro, des `Not a Number (NaN)` dans le jargon informatique. Comme ceux-ci représentent un nombre très faible d'électeurs nous allons les ignorer par rapport au reste de la population."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons d'abord compter le nombre de bureaux de vote qui n'ont aucun suffrage enregistré:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_1.sum(axis=1)==0).sum(), (df_2.sum(axis=1)==0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons \"effacer\" ces bureaux du vote en commençant par filtrer ceux qui n'ont aucun suffrage enregistré au premier tour :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2.drop(df_2.loc[df_1.sum(axis=1)==0].index, inplace=True)\n",
    "df_1.drop(df_1.loc[df_1.sum(axis=1)==0].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_1.sum(axis=1)==0).sum(), (df_2.sum(axis=1)==0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et maintenant répéter la même procédure sur les bureaux de vote qui n'ont aucun suffrage enregistré au second tour :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.drop(df_1.loc[df_2.sum(axis=1)==0].index, inplace=True)\n",
    "df_2.drop(df_2.loc[df_2.sum(axis=1)==0].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_1.sum(axis=1)==0).sum(), (df_2.sum(axis=1)==0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### statistiques de second ordre\n",
    "\n",
    "Comme cela est montré dans l'[article du Monde](https://www.lemonde.fr/les-decodeurs/article/2022/05/04/election-presidentielle-2022-quels-reports-de-voix-entre-les-deux-tours_6124672_4355770.html) on peut montrer la dépendance entre les choix qui sont effectués au premier tour et ceux qui sont effectués au deuxième tour. On va utiliser des représentations graphiques similaires à ceux de l'article pour d'une première part les répliquer et vérifier que la méthode est correct et d'un autre côté pour mieux comprendre comment nous pouvons tirer dans ses enseignements depuis ces observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_12 = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_12['1_MÉLENCHON'] = df_1['MÉLENCHON'].copy()\n",
    "df_12['MACRON'] = df_2['MACRON'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_12.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_12['1_MÉLENCHON'] = df_12['1_MÉLENCHON']/df_1.sum(axis=1)\n",
    "df_12['MACRON'] = df_12['MACRON']/df_2.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x=df_12['1_MÉLENCHON'], y=df_12['MACRON'], kind='hist', height=8);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque effectivement une dépendance entre le choix. Un premier candidat effectué au premier tour et celui qui est effectué au second tour. Nous allons essayer d'inférer de façon plus précise cette dépendance grâce au modèle de transition que nous avons exposer au début de cet article."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fit model de transfert des voix\n",
    "\n",
    "Tenant que nous avons récolté toutes les données pour les deux tours, et que nous avons une idée qu'il existe une dépendance entre les choix qui sont faits entre un tour et le suivant, nous allons pouvoir utiliser des librairies de tes apprentissage automatique machine Learning en anglais pour pouvoir insérer le report de voix entre les deux tours :. Pour cela nous allons utiliser un travail précédemment effectué appliquer à l'[exploration du comportement humain](https://laurentperrinet.github.io/sciblog/posts/2020-04-08-fitting-a-psychometric-curve-using-pytorch.html) ou alors pour [l'épidémiologie du Covid](https://laurentperrinet.github.io/sciblog/posts/2020-10-10-fitting-covid-data.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formatage des données au format de la librairie `torch`\n",
    "\n",
    "Pendant un aperçu des résultats au premier tour :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons donc comptabilisé ces différentes alternatives au premier tour :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_1.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De sorte que sur les bureaux de vote que nous avons validé nous avons les deux tableaux suivants :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_1.values.shape, df_2.values.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons maintenant utiliser la librairie `torch` pour enregistrer ses données sous la forme d'une matrice (ou tenseur dans le jargon de cette librairie) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "X_1, X_2 = df_1.values, df_2.values\n",
    "x_1, x_2 = torch.Tensor(X_1), torch.Tensor(X_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ainsi nous allons très facilement pouvoir représenter les données pour pouvoir les apprendre. Une pratique extrêmement importante dans l'apprentissage automatique et de séparer les données qui sont utilisés pour apprendre le modèle, avec celles qui sont utilisés pour tester ce modèle :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "dataset = TensorDataset(x_1, x_2)\n",
    "\n",
    "# Random split\n",
    "train_set_size = int(len(dataset) * 0.8)\n",
    "test_set_size = len(dataset) - train_set_size\n",
    "train_set, test_set = torch.utils.data.random_split(dataset, [train_set_size, test_set_size])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ainsi nous pourrons utiliser l'ensemble d'apprentissage au cours des différentes époques d'apprentissage utilisé plus bas :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n_1, n_2 in train_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En particulier nous allons couper les données de façon aléatoire puis il est représenté sous la forme de différents « paquet » dont la taille est fixé ici à 32, et nous verrons plus tard que si cette procédure permet d'accélérer l'apprentissage la taille du paquet n'a plus d'influence sur le résultat final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_1.shape, n_2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans chaque paquet nous pouvons compter le nombre de votes pour les différentes alternatives :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sum_1, sum_2 = n_1.sum(axis=1), n_2.sum(axis=1)\n",
    "sum_1, sum_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons aussi vérifier que parmi toutes les et les alternatives on peut calculer des fréquences d'occurrence, et que comme chaque individu peut faire un seul un choix est un seul, la somme de ses fréquences d'occurrence pour chacun des paquets est égal à $1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(n_1/sum_1[:, None]).sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pourrons aussi aisément utiliser les données qui sont représentés dans l'ensemble de test :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_1, n_2 = dataset[test_set.indices]\n",
    "n_1.shape, n_2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèle `torch` de transition de probabilités\n",
    "\n",
    "\n",
    "Maintenant que nous avons correctement formater les données, nous allons exprimer dans le langage de la librairie torche le modèle qui nous permet d'exprimer la transition entre les préférences au premier tour et les préférences au premier second tour. En particulier la matrice de transition sera définie par une matric `self.M` de telle sorte que quand on l'utilise, la contrainte qui fait que la somme des éléments colonne par colonne est bien égal à $1$ (utilisation de `torch.softmax(self.M, axis=0)`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#torch.set_default_tensor_type(\"torch.DoubleTensor\")\n",
    "torch.set_default_tensor_type(\"torch.FloatTensor\")\n",
    "\n",
    "class TransfertVoix(torch.nn.Module):\n",
    "    def __init__(self, N_1er, N_2eme):#, device=None):\n",
    "        super(TransfertVoix, self).__init__()\n",
    "        #if device is None: device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        #M = torch.randn((N_1er, N_2eme))\n",
    "        #self.M = torch.nn.Parameter(M, requires_grad=True)#.to(device)\n",
    "        self.lin = torch.nn.Linear(N_2eme, N_1er, bias=False)\n",
    "\n",
    "    def forward(self, p_1):\n",
    "        M = torch.softmax(self.lin.weight, axis=0)\n",
    "        #p_2_pred = torch.matmul(p_1, M)\n",
    "        p_2_pred = torch.matmul(p_1, M)\n",
    "        return p_2_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce modèle va utiliser comme dimension le nombre de différentes alternatives au premier et deuxième tour :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_1er, N_2eme = len(df_1.columns), len(df_2.columns)\n",
    "N_1er, N_2eme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De telle sorte que nous allons pouvoir instancier un tel modèle, sachant que la matrice de transition sera choisi de façon totalement aléatoire et donc déconnecté des données à l'initialisation de cet apprentissage :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = TransfertVoix(N_1er, N_2eme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in trans.parameters():print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans.lin.weight.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-22T15:14:03.579763Z",
     "iopub.status.busy": "2022-05-22T15:14:03.579510Z",
     "iopub.status.idle": "2022-05-22T15:14:03.589311Z",
     "shell.execute_reply": "2022-05-22T15:14:03.588646Z"
    }
   },
   "source": [
    "torch.softmax(trans.M, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous vérifions que la contrainte sur chaque colonne de la matrice de transition et bien vérifiée :"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-22T15:14:03.593698Z",
     "iopub.status.busy": "2022-05-22T15:14:03.593484Z",
     "iopub.status.idle": "2022-05-22T15:14:03.601021Z",
     "shell.execute_reply": "2022-05-22T15:14:03.600358Z"
    }
   },
   "source": [
    "torch.softmax(trans.M, axis=0).sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exprimons maintenant pour chacun des bureaux de vote les probabilités de préférence qui sont exprimées localement :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_1, sum_2 = n_1.sum(axis=1), n_2.sum(axis=1)\n",
    "p_1 = n_1/sum_1[:, None]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette probabilité va pouvoir être multiplié par la matrice de transition de probabilité et nous vérifions dans les lignes suivantes la compatibilité entre les différentes dimensions des données représentées :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_1.shape, p_1.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_1.shape, trans.lin.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.matmul(p_1, torch.softmax(trans.lin.weight, axis=0)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensordot(p_1, torch.softmax(trans.lin.weight, axis=0), dims=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ces différentes vérifications nous permettent de valider l'utilisation directe du modèle pour prédire la probabilité de préférence dans ce bureau de vote au second tour à partir de celle observée au premier tour :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_2_pred = trans(n_1/sum_1[:, None])\n",
    "p_2_pred.mean(axis=0), p_2_pred.mean(axis=0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Au cours de l'apprentissage, nous allons pouvoir comparer cette probabilité prédit avec celle qui a été effectivement observée :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_2 = n_2/sum_2[:, None]\n",
    "p_2.mean(axis=0), p_2.mean(axis=0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons aussi vérifier graphiquement que les résultats moyen des votes au second tour peuvent être inférer à partir des données de probabilité multiplié par la taille de chacun des bureaux de vote :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(13, 5))\n",
    "k = df_2.sum()/df_2.sum().sum()\n",
    "ax = k.plot.bar(ax=ax)\n",
    "p_2_average = (p_2*sum_2[:, None]).sum(axis=0)/sum_2.sum()\n",
    "ax.plot(p_2_average)\n",
    "ax.set_xlabel('Candidat')\n",
    "ax.set_ylabel('pourcentage');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ainsi que la concordance entre les résultats finaux obtenu est ce que nous représentons dans notre modèle :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k*100, p_2_average*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F.binary_cross_entropy(p_2_average, p_2_average, reduction=\"sum\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèle `torch` d'apprentissage\n",
    "\n",
    "Maintenant que nous avons défini le modèle de transition des probabilités entre les préférences au premier tour et au second tour, nous pouvons maintenant écrire un algorithme d'apprentissage qui permet d'optimiser la concordance entre la prédiction et les observations. \n",
    "\n",
    "Nous allons utiliser les distributions observées $q$ et prédites $\\hat{q}$ (celle-ci dépendant de $M$) pour calculer un coût à minimiser\n",
    "$$\n",
    "\\mathcal{L} =  KL(q, \\hat{q})\n",
    "$$\n",
    "\n",
    "où la [divergence de Kullback-Leibler](https://fr.wikipedia.org/wiki/Divergence_de_Kullback-Leibler) est calculée comme\n",
    "\n",
    "$$\n",
    "KL(P, Q) = \\sum_j P_j \\cdot \\log \\frac {P_j}{Q_j}\n",
    "$$\n",
    "\n",
    "\n",
    "Cette divergence est l'équivalent d'une distance dans les espaces de probabilité. Mathémamatiquement, c'est une semi-normes car elle obéit à deux propriétés fondamentales: elle est toujours positive et est égale à zéro quand elle est appliquée à distributions identiques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "learning_rate = 0.02\n",
    "beta1, beta2 = 0.9, 0\n",
    "# beta1, beta2 = 0.9, 0.999\n",
    "num_epochs = 2 ** 5 + 1\n",
    "batch_size = 2 ** 9\n",
    "do_optim = True\n",
    "do_optim = False\n",
    "\n",
    "def pdf_loss(p_pred, p, weight, loss_type):\n",
    "    if loss_type=='kl':\n",
    "        ind_nonzero = (p==0) + (p_pred==0)\n",
    "        p[ind_nonzero] = 1.\n",
    "        p_pred[ind_nonzero] = 1.\n",
    "        kl_div = p * (p.log() - p_pred.log())\n",
    "        loss_train = (kl_div * weight[:, None]).sum()\n",
    "    elif loss_type=='l1':\n",
    "        div = torch.absolute(p - p_pred)\n",
    "        loss_train = (div * weight[:, None]).sum() \n",
    "    else:\n",
    "        loss_train = F.binary_cross_entropy(p_pred, p, reduction=\"sum\", weight=weight[:, None])\n",
    "        loss_train -= F.binary_cross_entropy(p, p, reduction=\"sum\", weight=weight[:, None])\n",
    "    return loss_train\n",
    "\n",
    "def fit_data(\n",
    "    df_1,\n",
    "    df_2,\n",
    "    learning_rate=learning_rate,\n",
    "    batch_size=batch_size,\n",
    "    num_epochs=num_epochs,\n",
    "    loss_type='kl',\n",
    "    beta1=beta1,\n",
    "    beta2=beta2, \n",
    "    do_optim=do_optim, \n",
    "    split_ratio=.9, \n",
    "    seed=2022, # graine du générateur de nombre aléatoires utilisé dans le split test vs train\n",
    "    verbose=False\n",
    "):\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    N_1er, N_2eme = len(df_1.columns), len(df_2.columns)\n",
    "    trans = TransfertVoix(N_1er, N_2eme)\n",
    "    trans = trans.to(device)\n",
    "    trans.train()\n",
    "    \n",
    "    # apprentissage\n",
    "    if beta2==0: \n",
    "        optimizer = torch.optim.SGD(trans.parameters(), lr=learning_rate, momentum=beta1, nesterov=do_optim)\n",
    "    else:\n",
    "        optimizer = torch.optim.Adam(trans.parameters(), lr=learning_rate, betas=(beta1, beta2), amsgrad=do_optim)\n",
    "\n",
    "    if torch.cuda.is_available(): torch.cuda.empty_cache()    \n",
    "    # the data\n",
    "    X_1, X_2 = df_1.values, df_2.values\n",
    "    x_1, x_2 = torch.Tensor(X_1), torch.Tensor(X_2)\n",
    "\n",
    "    # split train and test\n",
    "    dataset = TensorDataset(x_1, x_2)\n",
    "    train_set_size = int(len(dataset) * split_ratio)\n",
    "    test_set_size = len(dataset) - train_set_size\n",
    "    train_set, test_set = random_split(dataset, [train_set_size, test_set_size], generator=torch.Generator().manual_seed(seed))\n",
    "    train_loader = DataLoader(train_set, batch_size=int(batch_size), shuffle=True)\n",
    "\n",
    "    for epoch in range(int(num_epochs)):\n",
    "        losses = []\n",
    "        for n_1, n_2 in train_loader:\n",
    "            n_1, n_2 = n_1.to(device), n_2.to(device)\n",
    "\n",
    "            sum_1, sum_2 = n_1.sum(axis=1), n_2.sum(axis=1)\n",
    "            p_1 = n_1/sum_1[:, None]\n",
    "            p_2 = n_2/sum_2[:, None]\n",
    "\n",
    "            p_2_pred = trans(p_1)\n",
    "            weight = sum_2 / train_set_size # /sum_2.sum() # donne un poids à chaque bureau de vote proportionnel à sa taille\n",
    "\n",
    "            loss_train = pdf_loss(p_2_pred, p_2, weight, loss_type=loss_type)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss_train.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            losses.append(loss_train.item())\n",
    "\n",
    "        if verbose and (epoch % (num_epochs // 32) == 0):\n",
    "            print(f\"Iteration: {epoch} / {num_epochs} - Loss: {np.sum(losses):.5e}\")\n",
    "\n",
    "    loss_train = np.sum(losses) # somme des loss à la dernière époque\n",
    "    loss_train = loss_train/split_ratio # normalise par rapport à la taille du train dataset\n",
    "\n",
    "    # Test\n",
    "    with torch.no_grad():\n",
    "        n_1, n_2 = dataset[test_set.indices]\n",
    "        sum_1, sum_2 = n_1.sum(axis=1), n_2.sum(axis=1)\n",
    "        p_2 = n_2/sum_2[:, None]\n",
    "        p_1 = n_1/sum_1[:, None]\n",
    "        p_2_pred = trans(p_1)\n",
    "        weight = sum_2 / test_set_size # normalise par rapport à la taille du test dataset\n",
    "        loss_test = pdf_loss(p_2_pred, p_2, weight, loss_type=loss_type)\n",
    "\n",
    "    return trans, loss_train, loss_test, p_1.detach().numpy(), p_2.detach().numpy(), p_2_pred.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for loss_type in ['kl', 'l1', 'bce']:\n",
    "    print(f'{loss_type=}')\n",
    "    trans, loss_train, loss_test, p_1, p_2, p_2_pred = fit_data(df_1, df_2, verbose=True, loss_type=loss_type)\n",
    "\n",
    "    fig, axs = plt.subplots(1, N_2eme, figsize=(13, 3))\n",
    "    for i_col, candidat in enumerate(df_2.columns):\n",
    "        #axs[i_col].scatter(p_2[:,i_col], p_2_pred[:,i_col], alpha=.005)\n",
    "        axs[i_col].plot([0, 1], [0, 1], 'r--')\n",
    "        sns.histplot(x=p_2[:, i_col], y=p_2_pred[:, i_col], ax=axs[i_col])\n",
    "        axs[i_col].set_xlabel(candidat)\n",
    "        axs[i_col].set_xlim(0, 1)\n",
    "        axs[i_col].set_ylim(0, 1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ces graphiques représentent en abscisse les probabilités observées et en ordonnée les probabilités prédites. L'intérieur du graphique représente au niveau de bleu l'histogramme des différentes valeurs telles qu'elles sont observés sur la base de test, c'est-à-dire sur 10 % de l'ensemble des bureeaux de vote."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut maintenant récupérer du modèle la matrice de transition qui a été inférée grâce a notre apprentissage automatique :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "M = torch.softmax(trans.lin.weight, axis=0).detach().numpy()\n",
    "M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On vérifie dans un premier temps que la contrainte est toujours bien respectée :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "M.sum(axis=0), M.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons nous inspirer d'[un graphique de la galerie matplotlib](https://matplotlib.org/stable/gallery/misc/table_demo.html#sphx-glr-gallery-misc-table-demo-py) pour représenter la la proportion des report de voir en fonction de chacun des choix FE au deuxième tour :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(13, 13))\n",
    "\n",
    "columns = df_2.columns\n",
    "rows = df_1.columns\n",
    "\n",
    "# Get some shades for the colors\n",
    "colors = plt.cm.tab20c(np.linspace(0, 1, len(rows)))\n",
    "n_rows = len(rows)\n",
    "\n",
    "index = np.arange(len(columns)) + 0.3\n",
    "bar_width = 0.4\n",
    "\n",
    "# Initialize the vertical-offset for the stacked bar chart.\n",
    "y_offset = np.zeros(len(columns))\n",
    "\n",
    "# Plot bars and create text labels for the table\n",
    "cell_text = []\n",
    "for row in range(n_rows):\n",
    "    ax.bar(index, M[row]*100, bar_width, bottom=y_offset, color=colors[row])\n",
    "    y_offset = y_offset + M[row]*100\n",
    "    cell_text.append([f'{x*100:1.1f}%' for x in M[row]])\n",
    "ax.set_ylim(0, 100)\n",
    "\n",
    "# Add a table at the bottom of the axes\n",
    "the_table = ax.table(cellText=cell_text,\n",
    "                      rowLabels=rows,\n",
    "                      rowColours=colors,\n",
    "                      colLabels=columns,\n",
    "                      loc='bottom')\n",
    "\n",
    "# Adjust layout to make room for the table:\n",
    "plt.subplots_adjust(left=0.2, bottom=0.2)\n",
    "\n",
    "plt.ylabel(\"Pourcentage de report des voix\")\n",
    "plt.yticks(np.linspace(0, 100, 6, endpoint=True))\n",
    "plt.xticks([])\n",
    "plt.title(\"Report des voix par résultat du 2nd tour\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C'est des données. Ces données correspondent aux intuitions qu'on peut se faire quand au report des votes. Notamment on remarque que la plupart des individus qui s'abstiennent au second tour se sont abstenus au premier (avec une petite proportion de Mélenchon qui se sont abstenus). Remarque aussi que la majorité des électeurs de Le Pen au premier tour en voter pour la même personne au deuxième tour. Environ un quart des électeurs de Le Pen au second tour s'était abstenu au premier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=1)\n",
    "np.set_printoptions(suppress=True)\n",
    "M*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On observe aussi quelques points intéressants dans les votes nuls qui proviennent majoritairement de voteur \"nul\" au premier tour (40 %) et ensuite par des électeurs ayant voté pour des candidats marginaux au premier tour (Arnaud, Lassalle, Hidalgo). On observe à peu près la même structure pour les voteurs \"blanc\" avec cette particularité que les individus ayant voté pour Jadot au premier tour ont relativement plus exprimé de votes \"blanc\" (~12 %) par rapport à ce qu'on observe pour les votes \"nul\". On rappelle qu'en France, un vote nul est un bulletin qui n'a pas été validé car il est par exemple raturé alors qu'un vote blanc est exprimé par un bulletin de vote totalement blanc (et qu'il faut préparer en avance). On peut donc expliquer ce dernier par rapport aux particularités du vote écologiques liés aux candidat Jadot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Muni de cette matrice de transition on peut maintenant opérer une transformation de telle sorte à ce que nous allons regarder la distribution des report de voix pour chacun des choix qui sont faits au premier tour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MT = M.T\n",
    "MT /= MT.sum(axis=0)\n",
    "MT*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(25, 8))\n",
    "\n",
    "columns = df_1.columns\n",
    "rows = df_2.columns\n",
    "\n",
    "# named colors: https://matplotlib.org/stable/gallery/color/named_colors.html\n",
    "colors = ['blueviolet', 'violet', 'darkviolet', 'steelblue', 'brown' ]\n",
    "n_rows = len(rows)\n",
    "\n",
    "index = np.arange(len(columns)) + 0.3\n",
    "bar_width = 0.4\n",
    "\n",
    "# Initialize the vertical-offset for the stacked bar chart.\n",
    "y_offset = np.zeros(len(columns))\n",
    "\n",
    "# Plot bars and create text labels for the table\n",
    "cell_text = []\n",
    "for row in range(n_rows):\n",
    "    ax.bar(index, MT[row]*100, bar_width, bottom=y_offset, color=colors[row], linewidth=1)\n",
    "    y_offset = y_offset + MT[row]*100\n",
    "    cell_text.append([f'{x*100:1.1f}%' for x in MT[row]])\n",
    "ax.set_ylim(0, 100)\n",
    "\n",
    "# Add a table at the bottom of the axes\n",
    "the_table = ax.table(cellText=cell_text,\n",
    "                      rowLabels=rows,\n",
    "                      rowColours=colors,\n",
    "                      colLabels=columns,\n",
    "                      loc='bottom')\n",
    "\n",
    "# Adjust layout to make room for the table:\n",
    "plt.subplots_adjust(left=0.2, bottom=0.2)\n",
    "\n",
    "plt.ylabel(\"Pourcentage de report des voix\")\n",
    "plt.yticks(np.linspace(0, 100, 6, endpoint=True))\n",
    "plt.xticks([])\n",
    "plt.title(\"Report des voix par résultat du 1er tour\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut aussi se restreindre aux votes exprimés :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MT = M[3:, 3:].T\n",
    "MT /= MT.sum(axis=0)\n",
    "MT*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 5))\n",
    "\n",
    "columns = df_1.columns[3:]\n",
    "rows = df_2.columns[3:]\n",
    "\n",
    "# named colors: https://matplotlib.org/stable/gallery/color/named_colors.html\n",
    "colors = ['steelblue', 'brown' ]\n",
    "n_rows = len(rows)\n",
    "\n",
    "index = np.arange(len(columns)) + 0.3\n",
    "bar_width = 0.4\n",
    "\n",
    "# Initialize the vertical-offset for the stacked bar chart.\n",
    "y_offset = np.zeros(len(columns))\n",
    "\n",
    "# Plot bars and create text labels for the table\n",
    "cell_text = []\n",
    "for row in range(n_rows):\n",
    "    ax.bar(index, MT[row]*100, bar_width, bottom=y_offset, color=colors[row], linewidth=1)\n",
    "    y_offset = y_offset + MT[row]*100\n",
    "    cell_text.append([f'{x*100:1.1f}%' for x in MT[row]])\n",
    "ax.set_ylim(0, 100)\n",
    "# Add a table at the bottom of the axes\n",
    "the_table = ax.table(cellText=cell_text, colLoc='center', \n",
    "                      rowLabels=rows, rowLoc='center',\n",
    "                      rowColours=colors,\n",
    "                      colLabels=columns,\n",
    "                      loc='bottom')\n",
    "the_table.auto_set_font_size(False)\n",
    "the_table.set_fontsize(10)\n",
    "# Adjust layout to make room for the table:\n",
    "plt.subplots_adjust(left=0.2, bottom=0.2)\n",
    "\n",
    "plt.ylabel(\"Pourcentage de report des voix\")\n",
    "plt.yticks(np.linspace(0, 100, 6, endpoint=True))\n",
    "plt.xticks([])\n",
    "plt.title(\"Report des voix exprimées connaissant le choix exprimé au 1er tour\")\n",
    "plt.savefig('2022-05-23_transfert-des-voix.png');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce tableau donne le pourcentage de chances d'exprimer une voix pour un candidat ou pour l'autre en fonction du choix qu'on a exprimé au premier tour. \n",
    "\n",
    "Ce tableau montre des tendances claires, par exemple que si on a voté Macron, Jadot ou Pécresse au premier tour, alors on va certainement voter Macron au deuxième tour. Ses électeurs se montre particulièrement consensuel et suivent le « pacte républicain » mise en place pour faire un barrage au Front National. Il montre aussi que si on a voté Le Pen ou Dupont-Aignan au premier tour alors on va voter Le Pen au deuxième, un clair vote de suivi. (On pourra aussi remarquer les ~ 3 % des voix pour Macron au premier tour qui ont voté Le Pen au deuxième tour, soit tout de même environ 320k individus…)\n",
    "\n",
    "Connaissant les couleurs politiques d'autres candidats du premier tour, on peut être surpris que les électeurs de Arthaud, Roussel ou Hidalgo ont majoritairement choisi Le Pen au deuxième tour, signifiant alors un rejet du candidat Macron. Les électeurs de Zemmour sont aussi partagés, signifiant un rejet des deux alternatives. **Ce résultat est à prendre avec des pincettes car ces derniers candidats ont obtenu moins de votes et donc que le processus d'inférence est forcément moins précis car il y a moins de données disponibles.** Pour se rendre compte de la variabilité des résultats qu'on obtient là, je conseille au lecteur (*à l'électeur*) de relancer ces notebook en utilisant différents « graines » pour le générateur de nombre aléatoire qui permet de séparer les données (le paramètre `seed`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"\"\"\n",
    "Total des voix au 1er tour= {x_1.sum():.0f}, dont Macron = {x_1[:, 5].sum():.0f} (soit une pourcentage de {x_1[:, 5].sum()/x_1.sum()*100:.2f}%), \n",
    "-> nombre de reports de Macron du 1er vers Le Pen au 2eme = {x_1[:, 5].sum()*MT[1, 2]:.0f} personnes.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### influence des parametres\n",
    "\n",
    "Finalement, on valide nos résultats en testant différentes paramétrisation de l'apprentissage et en donnant la valeur du loss calculé sur la base de test :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans, loss_train_alt, loss_test_alt, p_1, p_2, p_2_pred = fit_data(df_1, df_2, verbose=False, do_optim=not do_optim)\n",
    "print(f'TRAIN: Loss avec {do_optim=} = {loss_train:.2f} / Loss avec alternative choice do_optim={not do_optim} = {loss_train_alt:.2f} ')\n",
    "print(f'TEST: Loss avec {do_optim=} = {loss_test:.2f} / Loss avec alternative choice do_optim={not do_optim} = {loss_test_alt:.2f} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "N_scan = 7\n",
    "results_train, results_test = [], []\n",
    "\n",
    "learning_rates = learning_rate * np.logspace(-1, 1, 7, base=10)\n",
    "for learning_rate_ in learning_rates:\n",
    "    tic = time.time()\n",
    "    trans, loss_train, loss_test, p_1, p_2, p_2_pred = fit_data(df_1, df_2, learning_rate=learning_rate_, verbose=False)\n",
    "    print(f'Pour learning_rate= {learning_rate_:.2e}, {loss_train=:.2e} / {loss_test=:.2e}; le temps de calcul est {time.time()-tic:.3f} s')\n",
    "    results_train.append(loss_train)\n",
    "    results_test.append(loss_test)\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (13, 8))\n",
    "# ax.plot(learning_rates, results_train, '--')\n",
    "ax.plot(learning_rates, results_test)\n",
    "ax.set_xlabel = 'learning rate'\n",
    "ax.set_ylabel = 'Loss'\n",
    "ax.set_yscale('log');\n",
    "ax.set_xscale('log');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_train, results_test = [], []\n",
    "batch_sizes = (batch_size * np.arange(1, N_scan) ** 2) // 8\n",
    "print(batch_sizes)\n",
    "for batch_size_ in batch_sizes:\n",
    "    tic = time.time()\n",
    "    trans, loss_train, loss_test, p_1, p_2, p_2_pred = fit_data(df_1, df_2, batch_size=batch_size_, verbose=False)\n",
    "    print(f'Pour batch_size= {batch_size_}, {loss_train=:.2e} / {loss_test=:.2e}; le temps de calcul est {time.time()-tic:.3f} s')\n",
    "    results_train.append(loss_train)\n",
    "    results_test.append(loss_test)\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (13, 8))\n",
    "# ax.plot(batch_sizes, results_train, '--')\n",
    "ax.plot(batch_sizes, results_test)\n",
    "ax.set_xlabel = 'batch size'\n",
    "ax.set_ylabel = 'Loss'\n",
    "ax.set_yscale('log');\n",
    "ax.set_xscale('log');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta1s = 1 - (1 - beta1) * np.logspace(-1, 1, 7, base=10)\n",
    "print(beta1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_train, results_test = [], []\n",
    "beta1s = 1 - (1 - beta1) * np.logspace(-1, 1, 7, base=10)\n",
    "print(beta1s)\n",
    "for beta1_ in beta1s:\n",
    "    tic = time.time()\n",
    "    trans, loss_train, loss_test, p_1, p_2, p_2_pred = fit_data(df_1, df_2, beta1=beta1_, verbose=False)\n",
    "    print(f'Pour beta1= {beta1_:.2e}, {loss_train=:.2e} / {loss_test=:.2e}; le temps de calcul est {time.time()-tic:.3f} s')\n",
    "    results_train.append(loss_train)\n",
    "    results_test.append(loss_test)\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (13, 8))\n",
    "#ax.plot(beta1s, results_train, '--')\n",
    "ax.plot(beta1s, results_test)\n",
    "ax.set_xlabel = 'beta1'\n",
    "ax.set_ylabel = 'Loss';\n",
    "ax.set_yscale('log');\n",
    "#ax.set_xscale('log');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_train, results_test = [], []\n",
    "beta2s = 1 - (1 - .95) * np.logspace(-1, 1, 7, base=10)\n",
    "for beta2_ in beta2s:\n",
    "    tic = time.time()\n",
    "    trans, loss_train, loss_test, p_1, p_2, p_2_pred = fit_data(df_1, df_2, beta2=beta2_, verbose=False)\n",
    "    print(f'Pour beta2= {beta2_:.2e}, {loss_train=:.2e} / {loss_test=:.2e}; le temps de calcul est {time.time()-tic:.3f} s')\n",
    "    results_train.append(loss_train)\n",
    "    results_test.append(loss_test)\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (13, 8))\n",
    "# ax.plot(beta2s, results_train, '--')\n",
    "ax.plot(beta2s, results_test)\n",
    "ax.set_xlabel = 'beta2 with Adam instead of SGD'\n",
    "ax.set_ylabel = 'Loss'\n",
    "ax.set_yscale('log');\n",
    "ax.set_xscale('log');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_train, results_test = [], []\n",
    "num_epochss = ((num_epochs-1) * np.arange(1, N_scan) ** 2) // 8 + 1\n",
    "print(num_epochss)\n",
    "for num_epochs_ in num_epochss:\n",
    "    tic = time.time()\n",
    "    trans, loss_train, loss_test, p_1, p_2, p_2_pred = fit_data(df_1, df_2, num_epochs=num_epochs_, verbose=False)\n",
    "    print(f'Pour num_epochs={num_epochs_}, {loss_train=:.2e} / {loss_test=:.2e}; le temps de calcul est {time.time()-tic:.3f} s')\n",
    "    results_train.append(loss_train)\n",
    "    results_test.append(loss_test)\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (13, 8))\n",
    "#ax.plot(num_epochss, results_train, '--')\n",
    "ax.plot(num_epochss, results_test)\n",
    "ax.set_xlabel = 'batch size'\n",
    "ax.set_ylabel = 'Loss'\n",
    "ax.set_yscale('log');\n",
    "ax.set_xscale('log');"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Welcome To Colaboratory",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
